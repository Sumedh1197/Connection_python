{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTIMENT ANALYSIS ON THE IMDB DATASET  USING ML MODELS-\n",
      "\n",
      "1. INTRODUCTION\n",
      "\n",
      "Sentiment Analysis or Opinion Mining is the study of extraction, quantification and identification of subjective information using natural language processing, text analysis, computational linguistics and biometrics.\n",
      "Sentiment analysis can be used on a variety of data and for a variety of applications, it’s study has been one of the top research topics in recent times.  In today’s day and age people express their opinions on various products ,movies and other items using social media platforms such as twitter,facebook,instagram etc .One has to go through all the reviews for a particular item which is a laborious task and requires large amount of time.  Hence the role of Machine Learning in the present age is of utmost importance as it helps humans to create intelligent systems which predict the polarity of a text in a matter of seconds . This advancement in the field of artificial intelligence has helped us solving many real like problems in a time efficient manner.In this paper reviews from the IMDB dataset are analyzed and the machine learning models further classify the reviews into positive or negative. Implementation  of  various tasks was done using Python programming language and the results of the same are presented in the form of accuracies for various experiments.  In this paper real world problem of class imbalance is also addressed. This   is a scenario where the number of observations belonging to one class  is significantly lower than those belonging to the other class.  This problem is predominant in scenarios where anomaly detection is  crucial like electricity pilferage, fraudulent transactions in banks, identification of rare diseases, etc. In this situation, the predictive model developed using conventional machine learning algorithms could be biased and inaccurate.\n",
      "The following block diagram gives the idea of steps we have followed in this study:\n",
      "\n",
      "        \n",
      "                   \n",
      "\n",
      "At the end implementation of the latest trends in movie sentiment analysis was done i.e the deep learning approach . Usage of word embeddings was done  to train the neural model. The CNN model was used for classification.\n",
      "\n",
      "\n",
      "2. DATASET DESCRIPTION \n",
      " The IMDB dataset available online which was first used by [ Maas et al,2011] has been used in this sutdy . The dataset can be accessed at http://ai.Stanford.edu/amaas/data/sentiment/index.html\n",
      "We have made use of 50,000 movie reviews , it consists of equal positive and negative reviews( 25,000 each). We have made use of the csv file and loaded it into python , after which we have trained the supervised learning algorithms using different train-test splits. \n",
      "Using this dataset we have mimicked real life situations such as overfitting and class imbalance , and we have measured the accuracy of the models after applying feasible solutions for these problems . \n",
      "The dataset also consists of 50,000 unlabeled reviews. \n",
      "\n",
      "2.1 Visualization and description of data \n",
      "a. In this the description of the dataset used  is given, the various parameters and the factors affecting the classification are found using the python environment and results are displayed. Using the describe() function we have displayed the parameters such as count,standard deviation, different percentiles , mean , min and max . \n",
      "\n",
      "PARAMETERS\n",
      "VALUE\n",
      "1. Count of non NA values\n",
      "50000.000000\n",
      "2. Mean \n",
      "0.500000\n",
      "3. Standard Deviation \n",
      "0.500005\n",
      "4. Minimum Value\n",
      "0.000000\n",
      "5. 25%\n",
      "0.000000\n",
      "6. 50%\n",
      "0.500000\n",
      "7. 75%\n",
      "1.000000\n",
      "8. Maximum Value \n",
      "1.000000\n",
      "b. To do some visualization of our textual data  usage of wordcloud is done.The words cloud is a good choice for visualization, it is a visual representation of text data.It displays a list of words, the importance of each being shown with font size or color.This format is useful for quickly perceiving the most prominent terms. For this data viz, we use the python library wordcloud.\n",
      "\n",
      "WORDCLOUD FOR NEGATIVE TERMS\n",
      "\n",
      "\n",
      "      WORDCLOUD FOR POSITIVE TERMS \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3. PROBLEM STATEMENT \n",
      "In recent times the rise of predictive algorithms has been unprecedented , use of AI and its branches have been used for solving a variety of real life problems . Not only does this approach solve problems but it also makes life easier in many ways for many applications . The data we gather today is generally supervised and hence we have made use of the supervised dataset to create a real life situation. Using the different movie reviews we have attempted to create the problem and apply feasible solutions to the created problems in our dataset . The two problems we have recognized in this paper are : \n",
      "a- Train-test split accuracy\n",
      "b- Class Imbalance \n",
      "By playing around with our dataset we have approached these problems using simple solutions and checked the respective accuracies.  \n",
      "\n",
      "4. PROPOSED FRAMEWORK \n",
      "The skeleton of this study is being described in the flowchart below , everything about the flowchart is covered in the framework topic of this study . \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                                  \n",
      "\n",
      "\n",
      "\n",
      "1 .Pre processing of Dataset : \n",
      "First we have defined the data cleaning or pre processing function and  then applied it to the whole dataset.\n",
      "This function removes URL, remove HTML tags, handles negation words which are split into two parts, convert the words to lower cases, remove all non-letter characters. These elements are very common and they do not provide enough semantic information for the task hence we need to perform cleaning. Preprocessing is the first step to increasing accuracy of a classifier and it need not be a very complex task . Simple cleaning will provide you with good results and this has been proved in this study . \n",
      "\n",
      "   2.  Feature Extraction :\n",
      "            For feature extraction we have used two common and effective approaches i.e Bag of Words(BOW) and TF-IDF(Term Frequency Inverse Document Frequency) . Through our results we have obtained the most effective n-gram value for our dataset and this gives us highest accuracy with both our models. In the experimentation section we will showcase these values . \n",
      "2.1 Bag of Words \n",
      "According to Chaffar et.al. each sentence in the given dataset is represented by a feature vector composed of Boolean values for each word that occurs in a sentence. If a word is present then it’s corresponding value in the matrix is set to 1 else it is set to 0 . BOW considers words as independent entities and it does not take into consideration any semantic information from the text. However, it performs generally very well in text classification[ Chaffar et.al. 2011]. \n",
      "To make it simple let us consider a sentence  “It was the best of times” and we check the frequency of words from the 10 unique words randomly selected other than the words in the sentence , for example : worst,age,wisdom and foolishness . \n",
      "All these add up to 10 different words so BOW will consider each as a separate document and create a vector as given below.\n",
      "\n",
      "“it” = 1\n",
      "“was” = 1\n",
      "“the” = 1\n",
      "“best” = 1\n",
      "“of” = 1\n",
      "“times” = 1\n",
      "“worst” = 0\n",
      "“age” = 0\n",
      "“wisdom” = 0\n",
      "“foolishness” = 0\n",
      "VECTOR- “It was the best of times” = [1, 1, 1, 1, 1, 1, 0, 0, 0, 0].\n",
      "In this approach, each word or token is called a “gram”. Creating a vocabulary of two-word pairs is called a bigram model. In this way we can adjust the parameters the way we feel fit . Only disadvantage is a accuracy and computation time trade off, which means that as we increase the n-gram range the accuracy will increase but it will be computationally more expensive than a unigram or bigram model.\n",
      "The process of converting NLP text into numbers is called vectorization in ML.\n",
      "We have used two approaches to build a BOW model using the Machine Learning libraries available in Python : \n",
      "1. CountVectorizer \n",
      "CountVectorizer works on Terms Frequency, i.e. counting the occurrences of tokens and building a sparse matrix of documents x tokens.\n",
      "The reason behind of using this approach is that keyword or important signal will occur again and again. So if the number of occurrence represent the importance of word. More frequency means more importance.\n",
      "\n",
      "\n",
      "\n",
      "2. TfidfVectorizer \n",
      "This is the same vectorization that takes place in the TFIDF approach but here we specify the parameters as we did in CountVectorizer which we do not use in the next feature extraction method. It basically gives us the normalized count occurrence that is if you think that extremely high frequency may dominate the result and causing model bias. Normalization can be applied to pipeline easily.\n",
      "  \n",
      "2.2 Term Frequency Inverse Document Frequency (TF-IDF)\n",
      "\n",
      "According to [Li Ping et al ] the values of the vector elements Wi for a document d are calculated as a combination of the statistics TF(t,d) and DF(t). The term frequency TF(t,d) is the number of times word t occurs in document d. The document frequency DF(t) is the number of documents in which the word t occurs at least once. The inverse document frequency IDF(t) can be calculated from the document frequency\n",
      "                     \n",
      "\n",
      "|D|  is the total number of documents. The inverse document frequency of a word is low if it occurs in many documents and is highest if the word occurs in only one. The value Wi of features Ti for document d is then calculated as the product\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3. Classification Algorithms \n",
      "\n",
      "3.1 Logistic Regression \n",
      "Logistic regression measures the relationship between the categorical dependent variable and one or more independent variables by estimating probabilities using a logistic/sigmoid function.\n",
      "In this study binary logistic regression is used for classification of the reviews, being a very strong model it provides us with good accuracy with minimum training time. With the help of the Scikit-learn  package available in python the implementation of logistic regression is done . \n",
      "\n",
      "3.2 Support Vector Machine\n",
      "SVM’s are universal learners and can outperform Naïve Bayes in text categorization , they have proved to be highly effective for classification applications[Joachims 1998] . For implementing linear SVM too we have made the use of python’s Scikit-learn package . Both logistic regression and SVM gave us higher accuracy than other models and the results will be displayed in the experimentation. \n",
      "\n",
      "\n",
      "5.Literature Survey \n",
      "\n",
      "The sentiment analysis  has been an area of growing interest among many authors and their published works have given us a range of techniques compatible with sentiment analysis. Sentiment analysis has been applied at document level classification[Pang and Lee, 2004][ Turney, 2002][ Yan Zhao et al, 2014][ Richa Sharma et al, 2014] , it has been applied at sentence level [ Kim and Hovy , 2004] and lately feature level sentiment analysis is being carried out [Padmapani P. Tribhuvan et al, 2014][ S. ChandraKala and C. Sindhu, 2012]. The difference levels of sentiment analysis along with their tasks have been discussed by Seema et al in their study [Seema et al , 2015]. Pang et al used movie reviews for classification using traditional machine learning algorithms such as SVM,Logistic Regression and Naïve Bayes . In this study they concluded that these algorithms perform better  than human produced baselines and that SVM and logistic regression perform better than Naïve Bayes . They used n-gram techniques for feature selection i.e unigram , bi-gram and combination of them . Furthermore they concluded that in their experimentation unigram technique produced the best results in classification. [Pang et al,2002].  Annett et al. proposed a novel approach on Support Vector Machines by investigating variations of feature vectors involving different sizes of feature vectors, different feature representations, and different feature types.  They performed the lexical approach and machine learning approach for sentiment classification and concluded that the machine learning approach was more successful with better accuracy[Annett et al,2008].  Andrew L.Maas et al. introduced the IMDB dataset of 50,000 reviews for sentiment classification , their model is a mix of unsupervised and supervised techniques to learn word vectors capturing semantic document information as well as rich sentiment content. Their method performed better than Linear Discriminant  Analysis.  \n",
      "[Maas et al. 2011]. Justin Martineau and Tim Finin proposed a novel approach for sentiment analysis using Delta TFIDF instead of the normal TFIDF approach . In this their term frequency transformation boosts the importance of words that are unevenly distributed between the positive and negative classes and discounts evenly distributed words.  The value of an evenly distributed feature is zero. The more uneven the distribution the more important a feature should be. This method gives us a better idea of the features importance in the document for sentiment classification . They used SVM with a linear kernel for classification and concluded that delta TFIDF outperformed flat term frequencies and  TFIDF weights [Martineau et al , 2009] . Chakraborty et al  used the deep learning approach on the IMDB dataset provided by kaggle[ Kaggle] , they’ve made the use of google’s word2vec algorithm for application on the large dataset for classification so that the semantic information is observed. This model can be enhanced using the Doc2vec model too. In our study we have also used the deep learning approach for classification using Convolutional Neural Netoworks(CNN) and Gated Recurrent Unit(GRU) . Using word2vec model we have obtained word embeddings and obtained high accuracy [Chakraborty et al, 2018]. Sahu et al have followed a lexical approach using SentiWordNet[Bacianella et al,2010] to determine the overall polarity of the movie review. They have used the movie dataset available on rotten tomatoes comprising of 8000 polar movie reviews. Usage of different classification techniques such as Random Forest, KNN , COCR, Bagging and Naïve Bayes is done and different performance parameters are found out . In their study ,the  Random Forest technique obtained the highest accuracy of 88.95%.[Sahu et al,2016]. Manek et al have proposed the use of a Gini Index [Raileanu et al , 2004] based feature selection method with Support Vector Machine (SVM) classifier for sentiment classification  of a large movie review dataset. They obtained an impressive accuracy of 94.46% with the weight by  Gini Index method on the IMDB dataset of 50,000 reviews[ Maas et al]. Their proposed framework has improved accuracy than the other methods studied[Manek et al,2016]. Parkhe et al proposed an aspect based sentiment analysis of movie reviews[Parkhe and Biswas,2014]  . An Aspect Based Text Separator was used to separate text into aspects and different aspects used were screenplay, music, acting, plot, movie and direction. The aspect specific lexicon was used to separate the reviews aspect wise and each word in the lexicon was associated with the Part of Speech of that word. An  aspect classifiers such as Naïve Bayes was then used to output a 1 or -1 for positive and negative reviews respectively[Parkhe et al , 2015].\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6.Experimentation \n",
      "The dataset consists of 50,000 reviews which are equally divided into negative and positive(25,000 each ) , the preprocessing of the reviews was done in order to make training easier and increase testing accuracy . After pre-processing the clean data was used for feature extraction in order to train the classifiers , the common methods such as Bag of Words and the TF-IDF vectorizer was used . Classification accuracy was higher than expected for these traditional methods and that was because of the systematic cleaning of data along with the change in parameters for feature extraction. In the proposed framework we will discuss the various parameters used and how the accuracy increased on varying them. \n",
      "           For addressing the imbalance situation usage of  the confusion matrix has been done  to compare the accuracies  of different cases related to class imbalance. A class imbalance was created by reducing the number of positive reviews for training and keeping the negative reviews the same , the training of our models was done using this imbalance of reviews and the testing was done on a set with equal polarity of negative and positive reviews . It was  found that the model was inaccurately classifying the negative reviews and with this we created an imbalanced situation. In today’s world there are a lot of situations related to class imbalance and one of the main areas is for cancer detection using AI. We find a majority of negative cases and comparatively less positive ones so the model is trained on imbalanced data and this leads to inaccurate results which is deleterious for the outcome of the patients incase they are wrongly diagnosed . \n",
      "\n",
      "\n",
      "\n",
      "Our experimentation section is divided into two parts : \n",
      "6.1  Train-Test combinations- The main aim of this paper is to identify various real life situations and form a solution for the same. In Machine Learning problems the splitting of train and test is of utmost importance , accuracy and other performance parameters vary according  to  the split taken. Nowadays   more and more data is coming in which needs to be tested but the training is at times stagnant , in this approach we have calculated accuracy for different cases with more testing and less training examples. \n",
      "BOW PARAMETERS- Min_df=0, Max_df=4, Ngram range = 1,4 gives us best accuracy for bag of words . Only accuracy of SVM with countvectorizer decreases rest everything increases.  The n-gram range can be increased   but this increases number of features and hence the computation time. So a trade off is present between accuracy and computational cost. Changing of the parameters canbe done to get different accuracies on the test set  . So far we have implemented  : \n",
      "1. Min= 0 , max= 2, ngram range= 2,2\n",
      "2. Min=0, max= 5, ngram range= 1,4(long computation time)\n",
      "3. Min =0, max= 4, ngram range= 1,4 (long computation time)\n",
      "In the tables below we have listed the maximum accuracy obtained using the highlighted parameters .\n",
      "\n",
      "\n",
      "           Case1 \n",
      "Total Number of Reviews – 50,000 \n",
      "Train –Test split : 50%-50% \n",
      "Model\n",
      "TF-IDF\n",
      "BOW(TF-IDF)\n",
      "BOW(Count)\n",
      "1.Logistic Regression\n",
      "89.15%\n",
      "83.35%\n",
      "85.18%\n",
      "2.SVM\n",
      "89.45%\n",
      "85.75%\n",
      "84.38%\n",
      "\n",
      "Case2\n",
      "Total Number of Reviews- 50,000\n",
      "Train-Test split :  40%-60%\n",
      "Model\n",
      "TF-IDF\n",
      "BOW(TF-IDF)\n",
      "BOW(Count)\n",
      "1.Logistic Regression\n",
      "88.82%\n",
      "85.41%\n",
      "84.66%\n",
      "2.SVM\n",
      "89.24%\n",
      "85.45%\n",
      "83.80%\n",
      "\t\n",
      " \n",
      "\n",
      "Case3\n",
      "Total Number of Reviews- 50,000\n",
      "Train-Test split :  20%-80%\n",
      "Model\n",
      "TF-IDF\n",
      "BOW(TF-IDF)\n",
      "BOW(Count)\n",
      "1.Logistic Regression\n",
      "87.42%\n",
      "80.72%\n",
      "83.58%\n",
      "2.SVM\n",
      "87.98%\n",
      "83.69%\n",
      "82.80%\n",
      "\n",
      "\n",
      "\n",
      "Case4\n",
      "Total Number of Reviews- 50,000\n",
      "Train-Test split :  10%-90%\n",
      "Model\n",
      "TF-IDF\n",
      "BOW(TF-IDF)\n",
      "BOW(Count)\n",
      "1.Logistic Regression\n",
      "85.76%\n",
      "75.68%\n",
      "81.49%\n",
      "2.SVM\n",
      "86.74%\n",
      "81.38%\n",
      "80.61%\n",
      "\n",
      "\n",
      "6.2 Class Imbalance – To create a class imbalance in our training set we decreased the number of positive samples and kept the negative samples constant at 20,000 reviews. Four different cases were implemented and for each case calculation of  the accuracy and confusion matrix was done which gives us an indication of the imbalanced state. At the end a solution for the imbalanced situation was implemented using the under sampling method. The solution provided gives us a substantial increase in accuracy for all the feature extraction methods. This solution can also be implemented in real life applications where class imbalance occurs. The testing set consists of 10,000 reviews with equal negative and positive samples.The different cases with their accuracies have been shown below\n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "\n",
      "\n",
      "Case1\n",
      "Negative reviews- 20,000\n",
      "Positive Reviews- 10,000\n",
      "Model\n",
      "TF-IDF\n",
      "BOW(TF-IDF)\n",
      "BOW(Count)\n",
      "1.Logistic Regression\n",
      "83.87%\n",
      "50.01%\n",
      "50.36%\n",
      "2.SVM\n",
      "82.80%\n",
      "50.41%\n",
      "50.53%\n",
      "\n",
      "  \n",
      "\n",
      "    Confusion Matrix Tables(Case1):\n",
      "1. TF-IDF method\n",
      "Model \n",
      "True Positive\n",
      "True Negative\n",
      "False Negative\n",
      "False Positive\n",
      "1.Logistic Regression\n",
      "4784\n",
      "3603\n",
      "1397\n",
      "216\n",
      "2. SVM\n",
      "4695\n",
      "3585\n",
      "1415\n",
      "305\n",
      "\n",
      "2. Bag Of Words with TF-IDF vectorizer method\n",
      "Model \n",
      "True Positive\n",
      "True Negative\n",
      "False Negative\n",
      "False Positive\n",
      "1.Logistic Regression\n",
      "5000\n",
      "1\n",
      "4999\n",
      "0\n",
      "2. SVM\n",
      "4998\n",
      "43\n",
      "4957\n",
      "2\n",
      "\n",
      "3. Bag Of Words with Count vectorizer method\n",
      "Model \n",
      "True Positive\n",
      "True Negative\n",
      "False Positive\n",
      "False Negative\n",
      "1.Logistic Regression\n",
      "4999\n",
      "37\n",
      "4963\n",
      "1\n",
      "2. SVM\n",
      "4996\n",
      "57\n",
      "4943\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "Case2\n",
      "Negative reviews- 20,000\n",
      "Positive Reviews- 7500\n",
      "Model\n",
      "TF-IDF\n",
      "BOW(TF-IDF)\n",
      "BOW(Count)\n",
      "1.Logistic Regression\n",
      "80.34%\n",
      "50.00%\n",
      "50.25%\n",
      "2.SVM\n",
      "81.01%\n",
      "50.27%\n",
      "50.28%\n",
      "\n",
      "  \n",
      "\n",
      "    Confusion Matrix Tables(Case2):\n",
      "1. TF-IDF method\n",
      "Model \n",
      "True Positive\n",
      "True Negative\n",
      "False Negative\n",
      "False Positive\n",
      "1.Logistic Regression\n",
      "4876\n",
      "3158\n",
      "1842\n",
      "124\n",
      "2. SVM\n",
      "4754\n",
      "3347\n",
      "1653\n",
      "246\n",
      "\n",
      "2. Bag Of Words with TF-IDF vectorizer method\n",
      "Model \n",
      "True Positive\n",
      "True Negative\n",
      "False Negative\n",
      "False Positive\n",
      "1.Logistic Regression\n",
      "5000\n",
      "0\n",
      "5000\n",
      "0\n",
      "2. SVM\n",
      "4999\n",
      "28\n",
      "4972\n",
      "1\n",
      "\n",
      "3. Bag Of Words with Count vectorizer method\n",
      "Model \n",
      "True Positive\n",
      "True Negative\n",
      "False Negative\n",
      "False Positive\n",
      "1.Logistic Regression\n",
      "4999\n",
      "26\n",
      "4974\n",
      "1\n",
      "2. SVM\n",
      "4999\n",
      "29\n",
      "4971\n",
      "41\n",
      "\n",
      "\n",
      "\n",
      "            Case3\n",
      "Negative reviews- 20,000\n",
      "Positive Reviews- 5000\n",
      "Model\n",
      "TF-IDF\n",
      "BOW(TF-IDF)\n",
      "BOW(Count)\n",
      "1.Logistic Regression\n",
      "73.68%\n",
      "50.00%\n",
      "50.17%\n",
      "2.SVM\n",
      "77.95%\n",
      "50.20%\n",
      "50.18%\n",
      "\n",
      "  \n",
      "\n",
      "    Confusion Matrix Tables(Case3):\n",
      "1. TF-IDF method\n",
      "Model \n",
      "True Positive\n",
      "True Negative\n",
      "False Negative\n",
      "False Positive\n",
      "1.Logistic Regression\n",
      "4926\n",
      "2442\n",
      "2558\n",
      "74\n",
      "2. SVM\n",
      "4823\n",
      "2972\n",
      "2028\n",
      "177\n",
      "\n",
      "2. Bag Of Words with TF-IDF vectorizer method\n",
      "Model \n",
      "True Positive\n",
      "True Negative\n",
      "False Negative\n",
      "False Positive\n",
      "1.Logistic Regression\n",
      "5000\n",
      "0\n",
      "5000\n",
      "0\n",
      "2. SVM\n",
      "5000\n",
      "20\n",
      "4980\n",
      "0\n",
      "\n",
      "3. Bag Of Words with Count vectorizer method\n",
      "Model \n",
      "True Positive\n",
      "True Negative\n",
      "False Negative\n",
      "False Positive\n",
      "1.Logistic Regression\n",
      "4999\n",
      "18\n",
      "4982\n",
      "1\n",
      "2. SVM\n",
      "4999\n",
      "19\n",
      "4981\n",
      "1\n",
      "\n",
      "\n",
      "Case4\n",
      "Negative reviews- 20,000\n",
      "Positive Reviews- 1000\n",
      "Model\n",
      "TF-IDF\n",
      "BOW(TF-IDF)\n",
      "BOW(Count)\n",
      "1.Logistic Regression\n",
      "50.75%\n",
      "50.00%\n",
      "50.02%\n",
      "2.SVM\n",
      "59.45%\n",
      "50.02%\n",
      "50.01%\n",
      "\n",
      "  \n",
      "\n",
      "    Confusion Matrix Tables(Case4):\n",
      "1. TF-IDF method\n",
      "Model \n",
      "True Positive\n",
      "True Negative\n",
      "False Negative\n",
      "False Positive\n",
      "1.Logistic Regression\n",
      "4999\n",
      "76\n",
      "4924\n",
      "1\n",
      "2. SVM\n",
      "4992\n",
      "953\n",
      "4047\n",
      "8\n",
      "\n",
      "2. Bag Of Words with TF-IDF vectorizer method\n",
      "Model \n",
      "True Positive\n",
      "True Negative\n",
      "False Negative\n",
      "False Positive\n",
      "1.Logistic Regression\n",
      "5000\n",
      "0\n",
      "5000\n",
      "0\n",
      "2. SVM\n",
      "5000\n",
      "2\n",
      "4998\n",
      "0\n",
      "\n",
      "3. Bag Of Words with Count vectorizer method\n",
      "Model \n",
      "True Positive\n",
      "True Negative\n",
      "False Negative\n",
      "False Positive\n",
      "1.Logistic Regression\n",
      "5000\n",
      "2\n",
      "4998\n",
      "0\n",
      "2. SVM\n",
      "4999\n",
      "2\n",
      "4998\n",
      "1\n",
      "\n",
      "\n",
      "6.2.1 Class Imbalance Solution to increase accuracy \n",
      "As shown above the accuracy significantly decreases if the polarity of reviews are imbalanced. Hence in order to gain some accuracy we under sampled the negative reviews to bring them close to the positive ones.We took the first case of 10,000 positive reviews ,under sampled the negative reviews to 10,000 and tested it on the same test set. \n",
      "\n",
      "Positive reviews- 10,000\n",
      "Negative reviews- 10,000\n",
      "\n",
      "Model\n",
      "TF-IDF\n",
      "BOW(TF-IDF)\n",
      "BOW(Count)\n",
      "1.Logistic Regression\n",
      "86.93%\n",
      "83.04%\n",
      "79.29%\n",
      "2.SVM\n",
      "87.02%\n",
      "82.24%\n",
      "69.11%\n",
      "\t\n",
      "Confusion Matrix tables : \n",
      "\n",
      "1. TF-IDF method\n",
      "Model \n",
      "True Positive\n",
      "True Negative\n",
      "False Negative\n",
      "False Positive\n",
      "1.Logistic Regression\n",
      "4214\n",
      "4479\n",
      "521\n",
      "786\n",
      "2. SVM\n",
      "4301\n",
      "4401\n",
      "599\n",
      "699\n",
      "\n",
      "2. Bag Of Words with TF-IDF vectorizer method\n",
      "Model \n",
      "True Positive\n",
      "True Negative\n",
      "False Negative\n",
      "False Positive\n",
      "1.Logistic Regression\n",
      "4101\n",
      "4203\n",
      "797\n",
      "899\n",
      "2. SVM\n",
      "3998\n",
      "4226\n",
      "774\n",
      "1002\n",
      "\n",
      "3. Bag Of Words with Count vectorizer method\n",
      "Model \n",
      "True Positive\n",
      "True Negative\n",
      "False Negative\n",
      "False Positive\n",
      "1.Logistic Regression\n",
      "3784\n",
      "4145\n",
      "855\n",
      "1216\n",
      "2. SVM\n",
      "2023\n",
      "4888\n",
      "112\n",
      "2977\n",
      "\n",
      "\n",
      "   7. Deep Learning Approach \n",
      "7.1  Introduction \n",
      "To add on to  our implementation we found out the accuracy on our dataset using  deep learning  . Deep learning is numerous applications today , in most applications depending on learning technique used it surpasses the accuracy obtained by traditional machine learning algorithms. We have used the concept of word embeddings to train our model and obtained the accuracy using CNN.\n",
      "                                              DEEP LEARNING ARCHITECTURE                        \n",
      "\n",
      "\n",
      "EMBEDDING LAYER:\n",
      "Word Embedding is a representation of text where words that have the same meaning have a similar representation. In other words it represents words in a coordinate system where related words, based on a corpus of relationships, are placed closer together. In the deep learning frameworks such as TensorFlow, Keras, this part is usually handled by an embedding which stores a lookup table to map the words represented by numeric indexes to their dense vector representations.\n",
      "DEEP NETWORK \n",
      "Deep network takes the sequence of embedding vectors as input and converts them to a compressed representation. The compressed representation effectively captures all the information in the sequence of words in the text.\n",
      "FULLY CONNECTED LAYER \n",
      "The fully connected layer takes the deep representation from the RNN/LSTM/GRU and transforms it into the final output classes or class scores. This component is comprised of fully connected layers along with batch normalization and optionally dropout layers for regularization.\n",
      "OUTPUT LAYER \n",
      "Based on the necessity usage of  either Sigmoid for Binary classification or Softmax for multiclass  and Binary classification can be done.\n",
      "\n",
      "7.2 Framework \n",
      "In this approach we separately learn the word embeddings and pass it to the embedding layer. We have used the Gensim implementation of Word2Vec.The Word2Vec algorithm processes the document sentence by sentence. For implementation of this algorithm we have to initialize some parameters. Training of the model using the IMDB dataset consisting of 50,000 reviews was done and a vocabulary of size 101081 was obtained. After this we obtained the words most similar to ‘horrible’ \n",
      "\n",
      "The word embeddings are ready to use since the word2vec model was trained using the IMDB dataset. The embeddings are then loaded as a directory of words to vectors. The trained word embedding vector after mapping is then given to the embedding layer. During classification we specify the number of epochs to be run and finally obtain the accuracy for train and validation set.\n",
      "7.2.1 Classification Model\n",
      "CNN\n",
      "Yoon Kim reported a series of experiments and trained the CNN model on top of pre trained word vectors for sentence level classification tasks. The model with some hyperparameter tuning and static vector can achieve high accuracy.  CNN consists of n number of convolutional layers and pooling layers , there is a hidden layer after these and finally the output layer. Output from the convolution layer undergoes pooling, mainly used pooling method is max pooling after pooling. Dropout can be added when needed to improve accuracy.\n",
      " Specifications used to create CNN model : activation function used is sigmoid, 128 filters , kernel size of 5 , max pooling pool size is 2, loss is calculated using binary_crossentropy and optimizer used is adam.\n",
      "\n",
      "\n",
      "\n",
      "7.3 Accuracy \n",
      "In the table below we have calculated the change in validation accuracy with the change in number of epochs.\n",
      "EPOCHS\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "Accuracy \n",
      "85.43%\n",
      "85.57%\n",
      "85.61%\n",
      "85.45%\n",
      "\n",
      "Hence  highest accuracy was obtained with 20 epochs. \n",
      "8.Conclusion and future scope\n",
      "This study makes an attempt to classify the IMDB movie reviews dataset using logistic regression and SVM. Usage of different feature extraction methods have been done , it is observed that usage of TF-IDF approach generally gives a higher accuracy. The accuracy for Bag of Words approach also increases with increase in the n-gram range but the computation time for extracting features increases drastically. In the class imbalance situation the under sampling of negative reviews proved to be quite useful in increasing accuracy . The deep learning method provided a different approach to this problem and with proper variation of parameters an increase in accuracy can be obtained in the future.\n",
      "This study on sentiment analysis also has its limitations:\n",
      "1. It is observed that in many reviews usage of symbols make a big difference in obtaining the sentiment . However our models are not yet trained to make use of these.Further work needs to be studied regarding this.\n",
      "2. Reviews may not always be in the correct grammatical form eg Fine may be spelled as fineeee , great maybe spelled as greattt however the weightage of these words are not taken in their exact account.\n",
      "3. Computation time for extracting features makes the analysis a slow process, this happens with most feature extracting methods .\n",
      "\n",
      "Further work that can be examined in this area of sentiment analysis of movie reviews . In our class imbalance case if we can provide extra weight to the features extracted from the positive reviews than those extracted from the negative ones we can hope to improve accuracy further. The ratio of weights given to the positive and negative features should be the same as  the ratio of the positive-negative review split.  Hybrid techniques for feature extraction must also be studied to further improve the accuracy.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Reading of normal text files stored in your current working directory \n",
    "#In this notebook we will open a text files in python, read it line by line and then close the connection.\n",
    "#For opening text files use the function open with the file name in the argument. Set the mode = ‘r’ to read from a file.\n",
    "#Assign this to a variable and call the read() method. \n",
    "file= open('PAPER.txt',mode ='r')\n",
    "\n",
    "print(file.read())\n",
    "\n",
    "#After this do not forget to close the connection using the close method.\n",
    "\n",
    "file.close()\n",
    "\n",
    "#We can check if the connection is shut \n",
    "\n",
    "print(file.closed)\n",
    "\n",
    "#The text displayed is my research in the area of sentiment analysis using Machine Learning models in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTIMENT ANALYSIS ON THE IMDB DATASET  USING ML MODELS-\n",
      "\n",
      "\n",
      "\n",
      "1. INTRODUCTION\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We can also make use of context manager to avoid closing the connection to the file at all times. \n",
    "# Read & print the first 3 lines using \n",
    "#For large files, we may not want to print all of their content to the shell:you may wish to print only the first few lines. \n",
    "#Enter the readline() method, which allows you to do this. When a file called file is open, \n",
    "#you can print out the first line by executing file.readline(). \n",
    "#If you execute the same command again, the second line will print and so on.\n",
    "with open('PAPER.txt') as file:\n",
    "    print(file.readline())\n",
    "    print(file.readline())\n",
    "    print(file.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
